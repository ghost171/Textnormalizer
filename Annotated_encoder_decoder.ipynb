{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: False\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# we will use CUDA if it is available\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE=torch.device('cuda:0') # or set to 'cpu'\n",
    "print(\"CUDA:\", USE_CUDA)\n",
    "print(DEVICE)\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.trg_embed = trg_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
    "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
    "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
    "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask, src_lengths):\n",
    "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
    "    \n",
    "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
    "               decoder_hidden=None):\n",
    "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
    "                            src_mask, trg_mask, hidden=decoder_hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n",
    "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Applies a bidirectional GRU to sequence of embeddings x.\n",
    "        The input mini-batch x needs to be sorted by length.\n",
    "        x should have dimensions [batch, time, dim].\n",
    "        \"\"\"\n",
    "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        output, final = self.rnn(packed)\n",
    "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        # we need to manually concatenate the final states for both directions\n",
    "        fwd_final = final[0:final.size(0):2]\n",
    "        bwd_final = final[1:final.size(0):2]\n",
    "        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n",
    "\n",
    "        return output, final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
    "    \n",
    "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n",
    "                 bridge=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.attention = attention\n",
    "        self.dropout = dropout\n",
    "                 \n",
    "        self.rnn = nn.GRU(emb_size + 2 * hidden_size, hidden_size, num_layers,\n",
    "                          batch_first=True, dropout=dropout)\n",
    "                 \n",
    "        # to initialize from the final encoder state\n",
    "        self.bridge = nn.Linear(2 * hidden_size, hidden_size, bias=True) if bridge else None\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.pre_output_layer = nn.Linear(hidden_size + 2 * hidden_size + emb_size,\n",
    "                                          hidden_size, bias=False)\n",
    "        \n",
    "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
    "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
    "\n",
    "        # compute context vector using attention mechanism\n",
    "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
    "        context, attn_probs = self.attention(\n",
    "            query=query, proj_key=proj_key,\n",
    "            value=encoder_hidden, mask=src_mask)\n",
    "\n",
    "        # update rnn hidden state\n",
    "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "        \n",
    "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
    "        pre_output = self.dropout_layer(pre_output)\n",
    "        pre_output = self.pre_output_layer(pre_output)\n",
    "\n",
    "        return output, hidden, pre_output\n",
    "    \n",
    "    def forward(self, trg_embed, encoder_hidden, encoder_final, \n",
    "                src_mask, trg_mask, hidden=None, max_len=None):\n",
    "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
    "                                         \n",
    "        # the maximum number of steps to unroll the RNN\n",
    "        if max_len is None:\n",
    "            max_len = trg_mask.size(-1)\n",
    "\n",
    "        # initialize decoder hidden state\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(encoder_final)\n",
    "        \n",
    "        # pre-compute projected encoder hidden states\n",
    "        # (the \"keys\" for the attention mechanism)\n",
    "        # this is only done for efficiency\n",
    "        proj_key = self.attention.key_layer(encoder_hidden)\n",
    "        \n",
    "        # here we store all intermediate hidden states and pre-output vectors\n",
    "        decoder_states = []\n",
    "        pre_output_vectors = []\n",
    "        \n",
    "        # unroll the decoder RNN for max_len steps\n",
    "        for i in range(max_len):\n",
    "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
    "            output, hidden, pre_output = self.forward_step(\n",
    "              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
    "            decoder_states.append(output)\n",
    "            pre_output_vectors.append(pre_output)\n",
    "\n",
    "        decoder_states = torch.cat(decoder_states, dim=1)\n",
    "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
    "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
    "\n",
    "    def init_hidden(self, encoder_final):\n",
    "        \"\"\"Returns the initial decoder state,\n",
    "        conditioned on the final encoder state.\"\"\"\n",
    "\n",
    "        if encoder_final is None:\n",
    "            return None  # start with zeros\n",
    "\n",
    "        return torch.tanh(self.bridge(encoder_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        \n",
    "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
    "        key_size = 2 * hidden_size if key_size is None else key_size\n",
    "        query_size = hidden_size if query_size is None else query_size\n",
    "\n",
    "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
    "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
    "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
    "        \n",
    "        # to store attention scores\n",
    "        self.alphas = None\n",
    "        \n",
    "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
    "        assert mask is not None, \"mask is required\"\n",
    "\n",
    "        # We first project the query (the decoder state).\n",
    "        # The projected keys (the encoder states) were already pre-computated.\n",
    "        query = self.query_layer(query)\n",
    "        \n",
    "        # Calculate scores.\n",
    "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        \n",
    "        # Mask out invalid positions.\n",
    "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
    "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
    "        \n",
    "        # Turn scores to probabilities.\n",
    "        alphas = F.softmax(scores, dim=-1)\n",
    "        self.alphas = alphas        \n",
    "        \n",
    "        # The context vector is the weighted sum of the values.\n",
    "        context = torch.bmm(alphas, value)\n",
    "        \n",
    "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
    "        return context, alphas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "\n",
    "    attention = BahdanauAttention(hidden_size)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
    "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
    "        nn.Embedding(src_vocab, emb_size),\n",
    "        nn.Embedding(tgt_vocab, emb_size),\n",
    "        Generator(hidden_size, tgt_vocab))\n",
    "\n",
    "    return model.cuda() if USE_CUDA else model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"Object for holding a batch of data with mask during training.\n",
    "    Input is a batch from a torch text iterator.\n",
    "    \"\"\"\n",
    "    def __init__(self, src, trg, pad_index=0):\n",
    "        \n",
    "        src, src_lengths = src\n",
    "        \n",
    "        self.src = src\n",
    "        self.src_lengths = src_lengths\n",
    "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
    "        self.nseqs = src.size(0)\n",
    "        \n",
    "        self.trg = None\n",
    "        self.trg_y = None\n",
    "        self.trg_mask = None\n",
    "        self.trg_lengths = None\n",
    "        self.ntokens = None\n",
    "\n",
    "        if trg is not None:\n",
    "            trg, trg_lengths = trg\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_lengths = trg_lengths\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = (self.trg_y != pad_index)\n",
    "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            self.src = self.src.cuda()\n",
    "            self.src_mask = self.src_mask.cuda()\n",
    "\n",
    "            if trg is not None:\n",
    "                self.trg = self.trg.cuda()\n",
    "                self.trg_y = self.trg_y.cuda()\n",
    "                self.trg_mask = self.trg_mask.cuda()\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
    "    \"\"\"Standard Training and Logging Function\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    print_tokens = 0\n",
    "\n",
    "    for i, batch in enumerate(data_iter, 1):\n",
    "        \n",
    "        out, _, pre_output = model.forward(batch.src, batch.trg,\n",
    "                                           batch.src_mask, batch.trg_mask,\n",
    "                                           batch.src_lengths, batch.trg_lengths)\n",
    "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        print_tokens += batch.ntokens\n",
    "        \n",
    "        if model.training and i % print_every == 0:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (i, loss / batch.nseqs, print_tokens / elapsed))\n",
    "            start = time.time()\n",
    "            print_tokens = 0\n",
    "\n",
    "    return math.exp(total_loss / float(total_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(num_words=11, batch_size=16, num_batches=100, length=10, pad_index=0, sos_index=1):\n",
    "    \"\"\"Generate random data for a src-tgt copy task.\"\"\"\n",
    "    for i in range(num_batches):\n",
    "        data = torch.from_numpy(\n",
    "          np.random.randint(1, num_words, size=(batch_size, length)))\n",
    "        data[:, 0] = sos_index\n",
    "        data = data.cuda() if USE_CUDA else data\n",
    "        src = data[:, 1:]\n",
    "        trg = data\n",
    "        src_lengths = [length-1] * batch_size\n",
    "        trg_lengths = [length] * batch_size\n",
    "        yield Batch((src, src_lengths), (trg, trg_lengths), pad_index=pad_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"\"\"A simple loss compute and train function.\"\"\"\n",
    "\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
    "                              y.contiguous().view(-1))\n",
    "        loss = loss / norm\n",
    "\n",
    "        if self.opt is not None:\n",
    "            loss.backward()          \n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "        return loss.data.item() * norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
    "    \"\"\"Greedily decode a sentence.\"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
    "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    output = []\n",
    "    attention_scores = []\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out, hidden, pre_output = model.decode(\n",
    "              encoder_hidden, encoder_final, src_mask,\n",
    "              prev_y, trg_mask, hidden)\n",
    "\n",
    "            # we predict from the pre-output layer, which is\n",
    "            # a combination of Decoder state, prev emb, and context\n",
    "            prob = model.generator(pre_output[:, -1])\n",
    "\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data.item()\n",
    "        output.append(next_word)\n",
    "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
    "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
    "    \n",
    "    output = np.array(output)\n",
    "        \n",
    "    # cut off everything starting from </s> \n",
    "    # (only when eos_index provided)\n",
    "    if eos_index is not None:\n",
    "        first_eos = np.where(output==eos_index)[0]\n",
    "        if len(first_eos) > 0:\n",
    "            output = output[:first_eos[0]]      \n",
    "    \n",
    "    return output, np.concatenate(attention_scores, axis=1)\n",
    "  \n",
    "\n",
    "def lookup_words(x, vocab=None):\n",
    "    if vocab is not None:\n",
    "        x = [vocab.itos[i] for i in x]\n",
    "\n",
    "    return [str(t) for t in x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(example_iter, model, n=2, max_len=100, \n",
    "                   sos_index=1, \n",
    "                   src_eos_index=None, \n",
    "                   trg_eos_index=None, \n",
    "                   src_vocab=None, trg_vocab=None):\n",
    "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    print()\n",
    "    \n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        src_eos_index = None\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "        \n",
    "    for i, batch in enumerate(example_iter):\n",
    "      \n",
    "        src = batch.src.cpu().numpy()[0, :]\n",
    "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
    "\n",
    "        # remove </s> (if it is there)\n",
    "        src = src[:-1] if src[-1] == src_eos_index else src\n",
    "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
    "      \n",
    "        result, _ = greedy_decode(\n",
    "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
    "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
    "        print(\"Example #%d\" % (i+1))\n",
    "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
    "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
    "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
    "        print()\n",
    "        \n",
    "        count += 1\n",
    "        if count == n:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_copy_task():\n",
    "    \"\"\"Train the simple copy task.\"\"\"\n",
    "    num_words = 11\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=0)\n",
    "    model = make_model(num_words, num_words, emb_size=32, hidden_size=64)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "    eval_data = list(data_gen(num_words=num_words, batch_size=1, num_batches=100))\n",
    " \n",
    "    dev_perplexities = []\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        \n",
    "        print(\"Epoch %d\" % epoch)\n",
    "\n",
    "        # train\n",
    "        model.train()\n",
    "        data = data_gen(num_words=num_words, batch_size=32, num_batches=100)\n",
    "        run_epoch(data, model,\n",
    "                  SimpleLossCompute(model.generator, criterion, optim))\n",
    "\n",
    "        # evaluate\n",
    "        model.eval()\n",
    "        with torch.no_grad(): \n",
    "            perplexity = run_epoch(eval_data, model,\n",
    "                                   SimpleLossCompute(model.generator, criterion, None))\n",
    "            print(\"Evaluation perplexity: %f\" % perplexity)\n",
    "            dev_perplexities.append(perplexity)\n",
    "            print_examples(eval_data, model, n=2, max_len=9)\n",
    "        \n",
    "    return dev_perplexities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch Step: 50 Loss: 19.943550 Tokens per Sec: 3626.747921\n",
      "Epoch Step: 100 Loss: 17.628798 Tokens per Sec: 8747.188040\n",
      "Evaluation perplexity: 7.122339\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  1 2 9 1 2 9 1 2 9\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  6 6 6 6 6 6 6 6 6\n",
      "\n",
      "Epoch 1\n",
      "Epoch Step: 50 Loss: 15.387286 Tokens per Sec: 6705.464659\n",
      "Epoch Step: 100 Loss: 12.154882 Tokens per Sec: 7402.791608\n",
      "Evaluation perplexity: 3.590957\n",
      "\n",
      "Example #1\n",
      "Src :  9 9 1 6 10 9 2 2 3\n",
      "Trg :  9 9 1 6 10 9 2 2 3\n",
      "Pred:  9 6 9 9 2 10 2 9 1\n",
      "\n",
      "Example #2\n",
      "Src :  5 6 6 3 6 6 8 2 3\n",
      "Trg :  5 6 6 3 6 6 8 2 3\n",
      "Pred:  6 6 5 6 3 3 2 6 8\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13946/2687249398.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_perplexities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_copy_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"plot perplexities\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Perplexity per Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13946/1542204925.py\u001b[0m in \u001b[0;36mtrain_copy_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         run_epoch(data, model,\n\u001b[0;32m---> 22\u001b[0;31m                   SimpleLossCompute(model.generator, criterion, optim))\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13946/3861009335.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_iter, model, loss_compute, print_every)\u001b[0m\n\u001b[1;32m     12\u001b[0m                                            \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                            batch.src_lengths, batch.trg_lengths)\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnseqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtotal_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13946/2926618497.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, norm)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dev_perplexities = train_copy_task()\n",
    "\n",
    "def plot_perplexity(perplexities):\n",
    "    \"\"\"plot perplexities\"\"\"\n",
    "    plt.title(\"Perplexity per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.plot(perplexities)\n",
    "    \n",
    "plot_perplexity(dev_perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A REAL WORLD EXAMPLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/pytorch/text\n",
      "  Cloning git://github.com/pytorch/text to /tmp/pip-req-build-e2ltnw1f\n",
      "  Running command git clone -q git://github.com/pytorch/text /tmp/pip-req-build-e2ltnw1f\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Requirement already satisfied: spacy in /home/ghost/anaconda3/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: tqdm in /home/ghost/anaconda3/lib/python3.8/site-packages (from torchtext==0.11.0a0+05cb992) (4.50.2)\n",
      "Requirement already satisfied: requests in /home/ghost/anaconda3/lib/python3.8/site-packages (from torchtext==0.11.0a0+05cb992) (2.24.0)\n",
      "Requirement already satisfied: torch in /home/ghost/anaconda3/lib/python3.8/site-packages (from torchtext==0.11.0a0+05cb992) (1.9.0)\n",
      "Requirement already satisfied: numpy in /home/ghost/anaconda3/lib/python3.8/site-packages (from torchtext==0.11.0a0+05cb992) (1.21.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: setuptools in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (57.1.0)\n",
      "Requirement already satisfied: jinja2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (8.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ghost/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ghost/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.11.0a0+05cb992) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.11.0a0+05cb992) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.11.0a0+05cb992) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests->torchtext==0.11.0a0+05cb992) (1.25.11)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ghost/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/home/ghost/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.6 MB 66 kB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from en-core-web-sm==3.1.0) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (57.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.24.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.21.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.50.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.7)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.4)\n",
      "Requirement already satisfied: six in /home/ghost/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ghost/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ghost/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/home/ghost/anaconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
      "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
      "Collecting de-core-news-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.1.0/de_core_news_sm-3.1.0-py3-none-any.whl (18.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.8 MB 137 kB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from de-core-news-sm==3.1.0) (3.1.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: setuptools in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (57.1.0)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.3.2)\n",
      "Requirement already satisfied: jinja2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.11.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.21.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.24.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (8.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (4.50.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (20.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: six in /home/ghost/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.15.0)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/ghost/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ghost/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ghost/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/ghost/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ghost/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/home/ghost/anaconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip3 install git+git://github.com/pytorch/text spacy \n",
    "!python3 -m spacy download en\n",
    "!python3 -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LC_ALL=\"en_US.UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13946/2591755545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "from torchtext import data, datasets\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "if True:\n",
    "    import spacy\n",
    "    spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "    spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def tokenize_de(text):\n",
    "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "    print(\"KEk\")\n",
    "\n",
    "    UNK_TOKEN = \"<unk>\"\n",
    "    PAD_TOKEN = \"<pad>\"    \n",
    "    SOS_TOKEN = \"<s>\"\n",
    "    EOS_TOKEN = \"</s>\"\n",
    "    LOWER = True\n",
    "    \n",
    "    # we include lengths to provide to the RNNs\n",
    "    SRC = data.Field(tokenize=tokenize_de, \n",
    "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
    "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
    "    TRG = data.Field(tokenize=tokenize_en, \n",
    "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
    "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)\n",
    "\n",
    "    print(\"KEK\")\n",
    "    MAX_LEN = 25  # NOTE: we filter out a lot of sentences for speed\n",
    "    print(\"KEK\")\n",
    "    train_data, valid_data, test_data = datasets.IWSLT.splits(\n",
    "        exts=('.de', '.en'), fields=(SRC, TRG), \n",
    "        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "            len(vars(x)['trg']) <= MAX_LEN) \n",
    "    print(\"KEK\")\n",
    "    MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n",
    "    SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
    "    TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
    "    print(\"KEK\")\n",
    "    \n",
    "    PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('out_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>samples</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Әлеуметтік желілерде ЕЦ-166/5 төтенше қауіпсіз...</td>\n      <td>Әлеуметтік желілерде ЕЦ жүз алпыс алты бөлу бе...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Бұл – фейк, оны Нұр-Сұлтан қаласы бойынша ҚАЖД...</td>\n      <td>Бұл   фейк, оны Нұр Сұлтан қаласы бойынша ҚАЖД...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Кейбір желі қолданушылары мекеменің алдына қой...</td>\n      <td>Кейбір желі қолданушылары мекеменің алдына қой...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Шын мәнінде дәрігерлер колонияға созылмалы аур...</td>\n      <td>Шын мәнінде дәрігерлер колонияға созылмалы аур...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>«17 наурызда таңғы сағат 06:30 шамасында Нұр-С...</td>\n      <td>«он жетінші наурызда таңғы сағат алты отыз шам...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                             samples  \\\n0  Әлеуметтік желілерде ЕЦ-166/5 төтенше қауіпсіз...   \n1  Бұл – фейк, оны Нұр-Сұлтан қаласы бойынша ҚАЖД...   \n2  Кейбір желі қолданушылары мекеменің алдына қой...   \n3  Шын мәнінде дәрігерлер колонияға созылмалы аур...   \n4  «17 наурызда таңғы сағат 06:30 шамасында Нұр-С...   \n\n                                           predicted  \n0  Әлеуметтік желілерде ЕЦ жүз алпыс алты бөлу бе...  \n1  Бұл   фейк, оны Нұр Сұлтан қаласы бойынша ҚАЖД...  \n2  Кейбір желі қолданушылары мекеменің алдына қой...  \n3  Шын мәнінде дәрігерлер колонияға созылмалы аур...  \n4  «он жетінші наурызда таңғы сағат алты отыз шам...  "
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size = 0.8\n",
    "\n",
    "X = df.drop(columns = [\"predicted\"]).copy()\n",
    "y = df[\"predicted\"]\n",
    "\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.5\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3001781, 1)\n",
      "(3001781,)\n",
      "(375223, 1)\n",
      "(375223,)\n",
      "(375223, 1)\n",
      "(375223,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(None, None)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape), print(y_train.shape)\n",
    "print(X_valid.shape), print(y_valid.shape)\n",
    "print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "681727     Сонымен қатар, Қылмыстық кодекстің екі жүз тоқ...\n1025183    Баспасөз қызметінің мәліметінше, су тасқынынан...\n2698063    Б кезеңінде жаһандық жүйе пайда болды (бір мың...\n1188840    Ол қазіргі Атырау облысының Манаш ауылында дүн...\n2725731    Қосымша жіптен жүз елу алты шалу теріп алып, б...\n                                 ...                        \n2826766    Осының бәрі жергілікті халықтың кедейленіп, са...\n3024945    Боланден () — Германия Федеративтік Республика...\n3711233                                                 И \\n\n73991      Қарағанды облысының Шахтинск қаласында тұратын...\n1809507    Егер өсімдікті қараңғы жерде өсірсе, ол бозары...\nName: predicted, Length: 3001781, dtype: object"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>samples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>681727</th>\n      <td>Сонымен қатар, Қылмыстық кодекстің 297-бабы бо...</td>\n    </tr>\n    <tr>\n      <th>1025183</th>\n      <td>Баспасөз қызметінің мәліметінше, су тасқынынан...</td>\n    </tr>\n    <tr>\n      <th>2698063</th>\n      <td>Б кезеңінде жаһандық жүйе пайда болды (1750 — ...</td>\n    </tr>\n    <tr>\n      <th>1188840</th>\n      <td>Ол қазіргі Атырау облысының Манаш ауылында дүн...</td>\n    </tr>\n    <tr>\n      <th>2725731</th>\n      <td>Қосымша жіптен 156 шалу теріп алып, бірнеше қа...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2826766</th>\n      <td>Осының бәрі жергілікті халықтың кедейленіп, са...</td>\n    </tr>\n    <tr>\n      <th>3024945</th>\n      <td>Боланден () — Германия Федеративтік Республика...</td>\n    </tr>\n    <tr>\n      <th>3711233</th>\n      <td>И.\\n</td>\n    </tr>\n    <tr>\n      <th>73991</th>\n      <td>Қарағанды облысының Шахтинск қаласында тұратын...</td>\n    </tr>\n    <tr>\n      <th>1809507</th>\n      <td>Егер өсімдікті қараңғы жерде өсірсе, ол бозары...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3001781 rows × 1 columns</p>\n</div>",
      "text/plain": "                                                   samples\n681727   Сонымен қатар, Қылмыстық кодекстің 297-бабы бо...\n1025183  Баспасөз қызметінің мәліметінше, су тасқынынан...\n2698063  Б кезеңінде жаһандық жүйе пайда болды (1750 — ...\n1188840  Ол қазіргі Атырау облысының Манаш ауылында дүн...\n2725731  Қосымша жіптен 156 шалу теріп алып, бірнеше қа...\n...                                                    ...\n2826766  Осының бәрі жергілікті халықтың кедейленіп, са...\n3024945  Боланден () — Германия Федеративтік Республика...\n3711233                                               И.\\n\n73991    Қарағанды облысының Шахтинск қаласында тұратын...\n1809507  Егер өсімдікті қараңғы жерде өсірсе, ол бозары...\n\n[3001781 rows x 1 columns]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>samples</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Әлеуметтік желілерде ЕЦ-166/5 төтенше қауіпсіз...</td>\n      <td>Әлеуметтік желілерде ЕЦ жүз алпыс алты бөлу бе...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Бұл – фейк, оны Нұр-Сұлтан қаласы бойынша ҚАЖД...</td>\n      <td>Бұл   фейк, оны Нұр Сұлтан қаласы бойынша ҚАЖД...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Кейбір желі қолданушылары мекеменің алдына қой...</td>\n      <td>Кейбір желі қолданушылары мекеменің алдына қой...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Шын мәнінде дәрігерлер колонияға созылмалы аур...</td>\n      <td>Шын мәнінде дәрігерлер колонияға созылмалы аур...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>«17 наурызда таңғы сағат 06:30 шамасында Нұр-С...</td>\n      <td>«он жетінші наурызда таңғы сағат алты отыз шам...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3752222</th>\n      <td>Қазақтар шекара шебіндегі бекіністерге жүйелі ...</td>\n      <td>Қазақтар шекара шебіндегі бекіністерге жүйелі ...</td>\n    </tr>\n    <tr>\n      <th>3752223</th>\n      <td>Көтеріліске тағы да Жоламан батыр басшылық етт...</td>\n      <td>Көтеріліске тағы да Жоламан батыр басшылық етт...</td>\n    </tr>\n    <tr>\n      <th>3752224</th>\n      <td>Жоламан батыр бастаған қозғалыстың отаршылдыққ...</td>\n      <td>Жоламан батыр бастаған қозғалыстың отаршылдыққ...</td>\n    </tr>\n    <tr>\n      <th>3752225</th>\n      <td>Көтерілістің әр жерде шашыраңқы жүруі мен оған...</td>\n      <td>Көтерілістің әр жерде шашыраңқы жүруі мен оған...</td>\n    </tr>\n    <tr>\n      <th>3752226</th>\n      <td>Солай бола тұрса да ол Кенесары Қасымұлы баста...</td>\n      <td>Солай бола тұрса да ол Кенесары Қасымұлы баста...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3752227 rows × 2 columns</p>\n</div>",
      "text/plain": "                                                   samples  \\\n0        Әлеуметтік желілерде ЕЦ-166/5 төтенше қауіпсіз...   \n1        Бұл – фейк, оны Нұр-Сұлтан қаласы бойынша ҚАЖД...   \n2        Кейбір желі қолданушылары мекеменің алдына қой...   \n3        Шын мәнінде дәрігерлер колонияға созылмалы аур...   \n4        «17 наурызда таңғы сағат 06:30 шамасында Нұр-С...   \n...                                                    ...   \n3752222  Қазақтар шекара шебіндегі бекіністерге жүйелі ...   \n3752223  Көтеріліске тағы да Жоламан батыр басшылық етт...   \n3752224  Жоламан батыр бастаған қозғалыстың отаршылдыққ...   \n3752225  Көтерілістің әр жерде шашыраңқы жүруі мен оған...   \n3752226  Солай бола тұрса да ол Кенесары Қасымұлы баста...   \n\n                                                 predicted  \n0        Әлеуметтік желілерде ЕЦ жүз алпыс алты бөлу бе...  \n1        Бұл   фейк, оны Нұр Сұлтан қаласы бойынша ҚАЖД...  \n2        Кейбір желі қолданушылары мекеменің алдына қой...  \n3        Шын мәнінде дәрігерлер колонияға созылмалы аур...  \n4        «он жетінші наурызда таңғы сағат алты отыз шам...  \n...                                                    ...  \n3752222  Қазақтар шекара шебіндегі бекіністерге жүйелі ...  \n3752223  Көтеріліске тағы да Жоламан батыр басшылық етт...  \n3752224  Жоламан батыр бастаған қозғалыстың отаршылдыққ...  \n3752225  Көтерілістің әр жерде шашыраңқы жүруі мен оған...  \n3752226  Солай бола тұрса да ол Кенесары Қасымұлы баста...  \n\n[3752227 rows x 2 columns]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\\n    \"\"\" This prints some useful stuff about our data sets. \"\"\"\\n\\n    print(\"Data set sizes (number of sentence pairs):\")\\n    print(\\'train\\', len(train_data))\\n    print(\\'valid\\', len(valid_data))\\n    print(\\'test\\', len(test_data), \"\\n\")\\n\\n    print(\"First training example:\")\\n    print(\"src:\", \" \".join(vars(train_data[0])[\\'samples\\']))\\n    #print(\"trg:\", \" \".join(vars(src_field[0])[1]), \"\\n\")\\n\\n    #print(\"Most common words (src):\")\\n    #print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\\n    #print(\"Most common words (trg):\")\\n    #print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\\n\\n    #print(\"First 10 words (src):\")\\n    #print(\"\\n\".join(\\n    #    \\'%02d %s\\' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\\n    #print(\"First 10 words (trg):\")\\n    #print(\"\\n\".join(\\n    #    \\'%02d %s\\' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\\n\\n    print(\"Number of German words (types):\", len(src_field.vocab))\\n    print(\"Number of English words (types):\", len(trg_field.vocab), \"\\n\")\\n    \\n    \\nprint_data_info(X_train, X_valid, X_test, y_train, y_valid)'"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\n",
    "    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n",
    "\n",
    "    print(\"Data set sizes (number of sentence pairs):\")\n",
    "    print('train', len(train_data))\n",
    "    print('valid', len(valid_data))\n",
    "    print('test', len(test_data), \"\\n\")\n",
    "\n",
    "    print(\"First training example:\")\n",
    "    print(\"src:\", \" \".join(vars(train_data[0])['samples']))\n",
    "    #print(\"trg:\", \" \".join(vars(src_field[0])[1]), \"\\n\")\n",
    "\n",
    "    #print(\"Most common words (src):\")\n",
    "    #print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
    "    #print(\"Most common words (trg):\")\n",
    "    #print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
    "\n",
    "    #print(\"First 10 words (src):\")\n",
    "    #print(\"\\n\".join(\n",
    "    #    '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n",
    "    #print(\"First 10 words (trg):\")\n",
    "    #print(\"\\n\".join(\n",
    "    #    '%02d %s' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\n",
    "\n",
    "    print(\"Number of German words (types):\", len(src_field.vocab))\n",
    "    print(\"Number of English words (types):\", len(trg_field.vocab), \"\\n\")\n",
    "    \n",
    "    \n",
    "print_data_info(X_train, X_valid, X_test, y_train, y_valid)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(X_train, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs=10, lr=0.0003, print_every=100):\n",
    "    print(\"KEK\")\n",
    "\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    print(\"KEK\")\n",
    "    for epoch in num_epochs:\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>samples</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Әлеуметтік желілерде ЕЦ-166/5 төтенше қауіпсіз...</td>\n      <td>Әлеуметтік желілерде ЕЦ жүз алпыс алты бөлу бе...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Бұл – фейк, оны Нұр-Сұлтан қаласы бойынша ҚАЖД...</td>\n      <td>Бұл   фейк, оны Нұр Сұлтан қаласы бойынша ҚАЖД...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Кейбір желі қолданушылары мекеменің алдына қой...</td>\n      <td>Кейбір желі қолданушылары мекеменің алдына қой...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Шын мәнінде дәрігерлер колонияға созылмалы аур...</td>\n      <td>Шын мәнінде дәрігерлер колонияға созылмалы аур...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>«17 наурызда таңғы сағат 06:30 шамасында Нұр-С...</td>\n      <td>«он жетінші наурызда таңғы сағат алты отыз шам...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3752222</th>\n      <td>Қазақтар шекара шебіндегі бекіністерге жүйелі ...</td>\n      <td>Қазақтар шекара шебіндегі бекіністерге жүйелі ...</td>\n    </tr>\n    <tr>\n      <th>3752223</th>\n      <td>Көтеріліске тағы да Жоламан батыр басшылық етт...</td>\n      <td>Көтеріліске тағы да Жоламан батыр басшылық етт...</td>\n    </tr>\n    <tr>\n      <th>3752224</th>\n      <td>Жоламан батыр бастаған қозғалыстың отаршылдыққ...</td>\n      <td>Жоламан батыр бастаған қозғалыстың отаршылдыққ...</td>\n    </tr>\n    <tr>\n      <th>3752225</th>\n      <td>Көтерілістің әр жерде шашыраңқы жүруі мен оған...</td>\n      <td>Көтерілістің әр жерде шашыраңқы жүруі мен оған...</td>\n    </tr>\n    <tr>\n      <th>3752226</th>\n      <td>Солай бола тұрса да ол Кенесары Қасымұлы баста...</td>\n      <td>Солай бола тұрса да ол Кенесары Қасымұлы баста...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3752227 rows × 2 columns</p>\n</div>",
      "text/plain": "                                                   samples  \\\n0        Әлеуметтік желілерде ЕЦ-166/5 төтенше қауіпсіз...   \n1        Бұл – фейк, оны Нұр-Сұлтан қаласы бойынша ҚАЖД...   \n2        Кейбір желі қолданушылары мекеменің алдына қой...   \n3        Шын мәнінде дәрігерлер колонияға созылмалы аур...   \n4        «17 наурызда таңғы сағат 06:30 шамасында Нұр-С...   \n...                                                    ...   \n3752222  Қазақтар шекара шебіндегі бекіністерге жүйелі ...   \n3752223  Көтеріліске тағы да Жоламан батыр басшылық етт...   \n3752224  Жоламан батыр бастаған қозғалыстың отаршылдыққ...   \n3752225  Көтерілістің әр жерде шашыраңқы жүруі мен оған...   \n3752226  Солай бола тұрса да ол Кенесары Қасымұлы баста...   \n\n                                                 predicted  \n0        Әлеуметтік желілерде ЕЦ жүз алпыс алты бөлу бе...  \n1        Бұл   фейк, оны Нұр Сұлтан қаласы бойынша ҚАЖД...  \n2        Кейбір желі қолданушылары мекеменің алдына қой...  \n3        Шын мәнінде дәрігерлер колонияға созылмалы аур...  \n4        «он жетінші наурызда таңғы сағат алты отыз шам...  \n...                                                    ...  \n3752222  Қазақтар шекара шебіндегі бекіністерге жүйелі ...  \n3752223  Көтеріліске тағы да Жоламан батыр басшылық етт...  \n3752224  Жоламан батыр бастаған қозғалыстың отаршылдыққ...  \n3752225  Көтерілістің әр жерде шашыраңқы жүруі мен оған...  \n3752226  Солай бола тұрса да ол Кенесары Қасымұлы баста...  \n\n[3752227 rows x 2 columns]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghost/anaconda3/envs/myenv/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "model = make_model(len(df['samples']), len(df['predicted']),\n",
    "                   emb_size=256, hidden_size=256,\n",
    "                   num_layers=1, dropout=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/ghost/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:316184)",
      "at w.execute (/home/ghost/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:315573)",
      "at w.start (/home/ghost/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:311378)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/home/ghost/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:325786)",
      "at async t.CellExecutionQueue.start (/home/ghost/.vscode/extensions/ms-toolsai.jupyter-2021.6.832593372/out/client/extension.js:90:325326)"
     ]
    }
   ],
   "source": [
    "dev_perplexities = train(model, print_every=100)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('myenv': conda)",
   "name": "python3710jvsc74a57bd0809ecebc32aa3bf58f03e9c8fa59f2b8da1bd338679f330b35491bef5973dc5e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "809ecebc32aa3bf58f03e9c8fa59f2b8da1bd338679f330b35491bef5973dc5e"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}